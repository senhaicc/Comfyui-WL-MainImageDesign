"""
Comfyui-WL-MainImageDesign
Elite E-commerce Main Image Prompt Generator
Version: 2.0
"""

import json
import urllib.request
import urllib.error
import ssl
import base64
import io
import os
import numpy as np
from PIL import Image

# è·å–å½“å‰æ¨¡å—ç›®å½•
_CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))

def _load_prompt(filename):
    """ä»å¤–éƒ¨æ–‡ä»¶åŠ è½½ prompt"""
    prompt_file = os.path.join(_CURRENT_DIR, "prompts", filename)
    try:
        with open(prompt_file, "r", encoding="utf-8") as f:
            return f.read().strip()
    except FileNotFoundError:
        print(f"âš ï¸ Prompt file not found: {prompt_file}")
        return None
    except Exception as e:
        print(f"âš ï¸ Error loading prompt file {filename}: {e}")
        return None

def _load_system_prompt():
    """åŠ è½½ä¸» system prompt"""
    prompt = _load_prompt("system_prompt.txt")
    if prompt is None:
        print("âš ï¸ Falling back to default_prompt.txt")
        prompt = _load_prompt("default_prompt.txt")
    if prompt is None:
        raise FileNotFoundError("No prompt files found in prompts/ directory.")
    return prompt


class WLMainImageGenerator:
    """
    WL Main Image Design Generator
    ä¸“ä¸šç”µå•†ä¸»å›¾æç¤ºè¯ç”Ÿæˆå™¨ - è§†è§‰å†²å‡»åŠ›ä¼˜åŒ–ç‰ˆ
    """
    
    def __init__(self):
        pass

    def split_response_to_variants(self, text, prompt_count):
        """å°†å“åº”æ‹†åˆ†ä¸ºå¤šä¸ªå˜ä½“"""
        if text is None:
            return []

        s = str(text).replace("\r\n", "\n").replace("\r", "\n").strip()
        if not s:
            return []

        if prompt_count is None or int(prompt_count) <= 1:
            return [s]

        import re

        # å°è¯•åŒ¹é… JSON å¯¹è±¡æ¨¡å¼
        json_obj_pattern = r'\{\s*"prompt"\s*:\s*"'
        matches = list(re.finditer(json_obj_pattern, s))
        if len(matches) >= 2:
            parsed_objects = []
            idxs = [m.start() for m in matches]
            for i, start_idx in enumerate(idxs):
                end_idx = idxs[i + 1] if i + 1 < len(idxs) else len(s)
                chunk = s[start_idx:end_idx].strip().rstrip(',')
                try:
                    obj = json.loads(chunk)
                    if isinstance(obj, dict) and "prompt" in obj:
                        parsed_objects.append(obj["prompt"])
                    else:
                        parsed_objects.append(chunk)
                except json.JSONDecodeError:
                    clean = re.sub(r'^\s*\{\s*"prompt"\s*:\s*"', '', chunk)
                    clean = re.sub(r'"\s*\}\s*$', '', clean)
                    parsed_objects.append(clean)
            if parsed_objects:
                return parsed_objects

        # å°è¯•åŒ¹é…å˜ä½“å®šä½æ ‡è®°
        start_markers = [
            r"(?m)^\s*å˜ä½“å®šä½\s*[ï¼š:]",
            r"(?m)^\s*Variant Role\s*:",
            r"(?m)^\s*ä¸»æ ‡é¢˜\s*[ï¼š:]",
            r"(?m)^\s*Main Headline\s*:",
        ]
        for pat in start_markers:
            matches = list(re.finditer(pat, s))
            if len(matches) >= 2:
                idxs = [m.start() for m in matches] + [len(s)]
                parts = [s[idxs[i]:idxs[i + 1]].strip() for i in range(len(idxs) - 1)]
                parts = [p for p in parts if p]
                if parts:
                    return parts

        # å°è¯•ç”¨åˆ†éš”ç¬¦åˆ†å‰²
        if "\n---\n" in s:
            parts = [p.strip() for p in s.split("\n---\n")]
            parts = [p for p in parts if p]
            if parts:
                return parts

        # å°è¯•ç”¨å¤šä¸ªç©ºè¡Œåˆ†å‰²
        parts = [p.strip() for p in re.split(r"\n\s*\n\s*\n+", s)]
        parts = [p for p in parts if p]
        if len(parts) >= 2:
            return parts

        return [s]

    def _clean_code_fences(self, response_text):
        """æ¸…ç†ä»£ç å›´æ æ ‡è®°"""
        cleaned = (response_text or "").strip()
        if cleaned.startswith("```json"):
            cleaned = cleaned[7:]
        if cleaned.startswith("```"):
            cleaned = cleaned[3:]
        if cleaned.endswith("```"):
            cleaned = cleaned[:-3]
        return cleaned.strip()

    def _parse_response_to_prompts_list(self, response_text, expected_count):
        """è§£æå“åº”ä¸ºæç¤ºè¯åˆ—è¡¨"""
        method = "json"
        prompts_list = []
        try:
            cleaned = self._clean_code_fences(response_text)
            prompts_list = json.loads(cleaned)
            if not isinstance(prompts_list, list):
                method = "split:not_list"
                prompts_list = self.split_response_to_variants(response_text, expected_count)
        except json.JSONDecodeError:
            method = "split:json_decode_error"
            prompts_list = self.split_response_to_variants(response_text, expected_count)
        except Exception:
            method = "split:exception"
            prompts_list = self.split_response_to_variants(response_text, expected_count)

        normalized = []
        for item in prompts_list if isinstance(prompts_list, list) else [prompts_list]:
            text = self.extract_prompt_text(item)
            if text is None:
                continue
            normalized.append(self._strip_variant_role_header(text))

        if normalized:
            prompts_list = normalized
        else:
            prompts_list = []

        prompts_list = self.enforce_prompt_count(prompts_list, expected_count, response_text)
        if len(prompts_list) > expected_count:
            prompts_list = prompts_list[:expected_count]

        return prompts_list, method

    def _strip_variant_role_header(self, prompt_text):
        """ç§»é™¤å˜ä½“å®šä½å¤´éƒ¨ï¼ˆå¯é€‰ï¼‰"""
        if not isinstance(prompt_text, str):
            return prompt_text
        return prompt_text.strip()

    def _is_prompt_structurally_complete(self, prompt_text):
        """æ£€æŸ¥æç¤ºè¯æ˜¯å¦ç»“æ„å®Œæ•´"""
        if not isinstance(prompt_text, str):
            return False
        s = prompt_text.strip()
        if not s:
            return False

        has_main = ("ä¸»æ ‡é¢˜" in s) or ("Main Headline" in s)
        has_visual = ("è§†è§‰" in s) or ("Visual" in s) or ("å…‰å½±" in s) or ("Lighting" in s) or ("èƒŒæ™¯" in s) or ("Background" in s)

        return has_main and has_visual

    def enforce_prompt_count(self, prompts_list, prompt_count, raw_response):
        """ç¡®ä¿æç¤ºè¯æ•°é‡ç¬¦åˆè¦æ±‚"""
        try:
            pc = int(prompt_count)
        except Exception:
            pc = None

        if not pc or pc <= 0:
            return prompts_list

        if not prompts_list:
            return [str(raw_response)]

        if len(prompts_list) == pc:
            return prompts_list

        if len(prompts_list) > pc:
            return prompts_list[:pc]

        if len(prompts_list) == 1 and isinstance(prompts_list[0], str):
            parts = self.split_response_to_variants(prompts_list[0], pc)
            if parts and len(parts) >= pc:
                return parts[:pc]

        parts = self.split_response_to_variants(raw_response, pc)
        if parts and len(parts) >= pc:
            return parts[:pc]

        return prompts_list

    def extract_prompt_text(self, item):
        """æå–æç¤ºè¯æ–‡æœ¬"""
        if item is None:
            return None

        if isinstance(item, dict):
            prompt = item.get("prompt")
            if isinstance(prompt, str):
                return prompt
            return json.dumps(item, ensure_ascii=False)

        if isinstance(item, str):
            s = item.strip()
            if (s.startswith("{") and s.endswith("}")) or (s.startswith("[{") and s.endswith("}]")):
                try:
                    obj = json.loads(s)
                    if isinstance(obj, dict) and isinstance(obj.get("prompt"), str):
                        return obj["prompt"]
                except Exception:
                    pass

            return s.replace("\\n", "\n")

        return str(item)

    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "api_url": ("STRING", {
                    "multiline": False, 
                    "default": "https://api.openai.com/v1",
                }),
                "api_key": ("STRING", {
                    "multiline": False, 
                    "default": "", 
                    "placeholder": "sk-..."
                }),
                "model_name": ("STRING", {
                    "multiline": False, 
                    "default": "gemini-2.0-flash-exp",
                }),

                "product_type": ("STRING", {
                    "multiline": False,
                    "default": "è“ç‰™è€³æœº",
                }),
                "selling_points": ("STRING", {
                    "multiline": True,
                    "default": "é™å™ªã€é•¿ç»­èˆªã€ä½©æˆ´èˆ’é€‚",
                }),
                "design_style": (
                    [
                        "ç§‘æŠ€æ·±é‚ƒ (Tech Deep)",
                        "æ¸©æ¶¦ç±³ç™½ (Warm Cream)",
                        "é«˜çº§é‡‘æ£• (Premium Bronze)",
                        "æ¸…æ–°å¤©è“ (Fresh Sky)",
                        "æ°›å›´åœºæ™¯ (Lifestyle Scene)",
                        "ç¡¬æ ¸æ·±æ£• (Hardcore Brown)",
                        "æç®€çº¯å‡€ (Minimal Pure)",
                        "æœªæ¥ç§‘å¹» (Sci-Fi Future)",
                    ],
                    {"default": "ç§‘æŠ€æ·±é‚ƒ (Tech Deep)"}
                ),
                "aspect_ratio": (
                    [
                        "1:1 æ­£æ–¹å½¢ (800x800)",
                        "3:4 ç«–ç‰ˆ (600x800)",
                    ],
                    {"default": "1:1 æ­£æ–¹å½¢ (800x800)"}
                ),
                "price_display": (
                    [
                        "å¤§ä¿ƒä»·æ ¼å— (Â¥XX + åˆ’çº¿åŸä»·)",
                        "è§’æ ‡ä¿ƒé”€ä»· (å·¦ä¸‹åœ†è§’æ¡†)",
                        "åŒä»·å¯¹æ¯” (å›½è¡¥ä»· vs åŸä»·)",
                        "ä¸æ˜¾ç¤ºä»·æ ¼",
                    ],
                    {"default": "å¤§ä¿ƒä»·æ ¼å— (Â¥XX + åˆ’çº¿åŸä»·)"}
                ),
                "price_value": ("STRING", {
                    "multiline": False,
                    "default": "Â¥299",
                    "placeholder": "Â¥299 æˆ– $49.99"
                }),
                "original_price": ("STRING", {
                    "multiline": False,
                    "default": "Â¥599",
                    "placeholder": "åˆ’çº¿åŸä»· Â¥599"
                }),
                "promo_type": (
                    [
                        "TOPæ’åå¾½ç«  (çƒ­é”€ç¬¬1å)",
                        "é™æ—¶æŠ˜æ‰£æ ‡ç­¾ (é™æ—¶XæŠ˜/ç«‹å‡XX)",
                        "ä¹°èµ æ´»åŠ¨æ¡† (ä¹°2èµ 1)",
                        "æ–°å“é¦–å‘æ ‡ç­¾",
                        "å®˜æ–¹æ­£å“å¾½ç« ",
                        "è®¤è¯æ ‡ç­¾ (ACS/SGS/Hi-Res)",
                        "æ— ä¿ƒé”€æ ‡ç­¾",
                    ],
                    {"default": "TOPæ’åå¾½ç«  (çƒ­é”€ç¬¬1å)"}
                ),
                "trust_bar": ("STRING", {
                    "multiline": False,
                    "default": "é¡ºä¸°åŒ…é‚®|ä¸‰å¹´è´¨ä¿|7å¤©æ— ç†ç”±",
                    "placeholder": "ä¿¡ä»»æ¨ªæ¡å†…å®¹ï¼Œç”¨|åˆ†éš”"
                }),
                "output_language": (
                    [
                        "ä¸­æ–‡ (Chinese)",
                        "English",
                    ],
                    {"default": "ä¸­æ–‡ (Chinese)"}
                ),
                "seed": ("INT", {"default": 0, "min": 0, "max": 99999}),
                "prompt_count": ("INT", {"default": 3, "min": 1, "max": 10, "forceInput": False})
            },
            "optional": {
                "product_image": ("IMAGE",),
                "product_image_2": ("IMAGE",),
                "product_image_3": ("IMAGE",),
                "product_image_4": ("IMAGE",),
            }
        }

    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("prompts_list", "debug_info")
    OUTPUT_IS_LIST = (True, False)

    FUNCTION = "generate_main_image_prompts"
    CATEGORY = "ğŸ¨ WL-MainImageDesign"

    def tensor_to_base64(self, image, index=0):
        """å°† ComfyUI Tensor å›¾ç‰‡è½¬æ¢ä¸º Base64"""
        if image is None:
            return None

        img_tensor = image
        try:
            if hasattr(image, "shape") and len(image.shape) == 4:
                img_tensor = image[index]
        except Exception:
            img_tensor = image

        i = 255. * img_tensor.cpu().numpy()
        img = Image.fromarray(np.clip(i, 0, 255).astype(np.uint8))

        max_size = 1024
        if img.width > max_size or img.height > max_size:
            img.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)

        buffered = io.BytesIO()
        img.save(buffered, format="JPEG", quality=85)
        img_str = base64.b64encode(buffered.getvalue()).decode("utf-8")
        return f"data:image/jpeg;base64,{img_str}"

    def collect_base64_images(self, images, max_images=6):
        """æ”¶é›†å¤šå¼ å›¾ç‰‡çš„ Base64 ç¼–ç """
        base64_images = []

        if images is None:
            return base64_images

        for img in images:
            if img is None:
                continue

            try:
                if hasattr(img, "shape") and len(img.shape) == 4:
                    batch = int(img.shape[0])
                    for bi in range(batch):
                        if len(base64_images) >= max_images:
                            return base64_images
                        base64_images.append(self.tensor_to_base64(img, bi))
                else:
                    if len(base64_images) >= max_images:
                        return base64_images
                    base64_images.append(self.tensor_to_base64(img, 0))
            except Exception:
                if len(base64_images) >= max_images:
                    return base64_images
                base64_images.append(self.tensor_to_base64(img, 0))

        return [b for b in base64_images if b]

    def call_llm_vision(self, api_url, api_key, model, system_prompt, user_prompt, base64_images=None, seed=None):
        """è°ƒç”¨ LLM Vision API"""
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}",
            "User-Agent": "ComfyUI-WL-MainImageDesign/2.0"
        }

        url = api_url.rstrip('/')
        if url.endswith('/chat'):
            url = f"{url}/completions"
        elif not url.endswith('/chat/completions'):
            url = f"{url}/chat/completions"

        content_list = [{"type": "text", "text": user_prompt}]
        if base64_images:
            if isinstance(base64_images, str):
                base64_images = [base64_images]
            for base64_image in base64_images:
                if not base64_image:
                    continue
                content_list.append({
                    "type": "image_url",
                    "image_url": {
                        "url": base64_image
                    }
                })

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": content_list}
        ]

        payload = {
            "model": model,
            "messages": messages,
            "max_tokens": 8192,
            "temperature": 0.75,
            "stream": False
        }
        
        if seed is not None and seed > 0:
            payload["seed"] = seed

        try:
            print(f"ğŸ”— Calling API: {url}")
            print(f"ğŸ¨ Model: {model}")
            
            ssl_context = ssl._create_unverified_context()
            
            req = urllib.request.Request(url, data=json.dumps(payload).encode('utf-8'), headers=headers)
            with urllib.request.urlopen(req, timeout=180, context=ssl_context) as response:
                result = json.loads(response.read().decode('utf-8'))
                return {"success": True, "content": result['choices'][0]['message']['content']}
        except urllib.error.HTTPError as e:
            err_body = e.read().decode('utf-8')
            error_msg = f"HTTP Error {e.code}: {err_body}"
            print(f"âŒ {error_msg}")
            return {"success": False, "error": error_msg}
        except urllib.error.URLError as e:
            error_msg = f"URL Error: {str(e)}\nAPI URL: {url}"
            print(f"âŒ {error_msg}")
            return {"success": False, "error": error_msg}
        except Exception as e:
            error_msg = f"Error: {str(e)}\nAPI URL: {url}"
            print(f"âŒ {error_msg}")
            return {"success": False, "error": error_msg}

    def generate_main_image_prompts(self, api_url, api_key, model_name, product_type, selling_points, 
                                     design_style, aspect_ratio, price_display, price_value, original_price,
                                     promo_type, trust_bar, output_language, seed, prompt_count, 
                                     product_image=None, product_image_2=None, product_image_3=None, product_image_4=None):
        """ç”Ÿæˆé«˜è§†è§‰å†²å‡»åŠ›ä¸»å›¾æç¤ºè¯"""
        
        base64_images = self.collect_base64_images(
            [product_image, product_image_2, product_image_3, product_image_4],
            max_images=6
        )

        # åŠ è½½ system prompt
        system_instruction = _load_system_prompt()
            
        # è¯­è¨€å¤„ç†
        if output_language == "ä¸­æ–‡ (Chinese)":
            lang_instruction = "è¯·ä½¿ç”¨ä¸­æ–‡ç”Ÿæˆæ‰€æœ‰æç¤ºè¯å†…å®¹ã€‚æ¨¡å—æ ‡é¢˜ä½¿ç”¨ï¼šä¸»æ ‡é¢˜/å‰¯æ ‡é¢˜/ä»·æ ¼ä¿ƒé”€åŒº/æ’ç‰ˆè“å›¾/è§†è§‰ä¸å…‰å½±/æ¸²æŸ“å“è´¨"
            anti_translate = "ç”»é¢æ‰€æœ‰æ–‡å­—å¿…é¡»ä¸ºä¸­æ–‡ï¼Œç¦æ­¢å‡ºç°ä»»ä½•è‹±æ–‡å­—æ¯æˆ–ä¹±ç ï¼Œæ–‡å­—æ¸²æŸ“æ¸…æ™°é”åˆ©ã€‚"
        else:
            lang_instruction = "Generate all prompt content in English. Use module headers: Main Headline/Sub Headline/Price & Promo Zone/Layout Blueprint/Visual & Lighting/Render Quality"
            anti_translate = "All text must be in English only. No Chinese characters. Text rendering must be crystal clear."

        # æ¯”ä¾‹å¤„ç†
        if "1:1" in aspect_ratio:
            ratio_instruction = """1:1æ­£æ–¹å½¢(800x800)æ’ç‰ˆï¼š
- é¡¶éƒ¨åŒº(0-22%)ï¼šä¸»æ ‡é¢˜42ptç­‰æ•ˆå¤§å­—ï¼Œå±…ä¸­æˆ–å·¦å¯¹é½
- ä¸Šä¸­åŒº(18-38%)ï¼šå‰¯æ ‡é¢˜/3-5ä¸ªå–ç‚¹å›¾æ ‡
- ä¸­å¿ƒåŒº(25-75%)ï¼šäº§å“ä¸»ä½“å 45-60%ï¼Œæ‚¬æµ®æ•ˆæœ
- ä¸‹ä¸­åŒº(65-82%)ï¼šè§„æ ¼å‚æ•°/è®¤è¯æ ‡ç­¾
- åº•éƒ¨åŒº(78-100%)ï¼šä»·æ ¼+ä¿ƒé”€æ ‡ç­¾+ä¿¡ä»»æ¨ªæ¡"""
            ratio_code = "1:1"
        else:
            ratio_instruction = """3:4ç«–ç‰ˆ(600x800)æ’ç‰ˆï¼š
- é¡¶éƒ¨åŒº(0-18%)ï¼šä¸»æ ‡é¢˜42ptç­‰æ•ˆå¤§å­—
- ä¸Šéƒ¨åŒº(15-32%)ï¼šå‰¯æ ‡é¢˜/ä¿ƒé”€å°å­—
- ä¸­å¿ƒåŒº(28-72%)ï¼šäº§å“ä¸»ä½“å 50-65%ï¼Œæ›´å¤šå‚ç›´ç©ºé—´
- ä¸‹éƒ¨åŒº(68-85%)ï¼šè¯¦ç»†è§„æ ¼/è®¤è¯
- åº•éƒ¨åŒº(82-100%)ï¼šä»·æ ¼+CTA+ä¿¡ä»»å…ƒç´ """
            ratio_code = "3:4"

        # é£æ ¼è¯¦ç»†æè¿°
        style_details = {
            "ç§‘æŠ€æ·±é‚ƒ (Tech Deep)": """èƒŒæ™¯ï¼šæ·±è“æ¸å˜(#1a1a2eâ†’#16213eâ†’#0f3460)
å…‰æ•ˆï¼šè“ç´«è‰²è¾¹ç¼˜å…‰æ™•ï¼Œå‡ ä½•ç§‘æŠ€çº¿æ¡
ç²’å­ï¼šå¾®å¦™çš„ç§‘æŠ€ç½‘æ ¼æˆ–ç”µè·¯å›¾æ¡ˆ
æ°›å›´ï¼šæœªæ¥æ„Ÿã€ä¸“ä¸šæ„Ÿã€é«˜ç«¯ç§‘æŠ€""",
            
            "æ¸©æ¶¦ç±³ç™½ (Warm Cream)": """èƒŒæ™¯ï¼šå¥¶æ²¹æ¸å˜(#fefefeâ†’#f5f0e8â†’#e8e0d5)
å…‰æ•ˆï¼šå·¦ä¸Šè§’æš–é˜³å…‰ï¼ŒæŸ”å’Œæ¼«å°„
çº¹ç†ï¼šå¾®å¦™äºšéº»æˆ–çº¸å¼ è´¨æ„Ÿ
æ°›å›´ï¼šæ¸©é¦¨ã€å®¶å±…æ„Ÿã€å“è´¨ç”Ÿæ´»""",
            
            "é«˜çº§é‡‘æ£• (Premium Bronze)": """èƒŒæ™¯ï¼šé‡‘æ£•æ¸å˜(#d4a574â†’#c9a067)ï¼Œå¾®å¦™
å…‰æ•ˆï¼šé‡‘è‰²è¾¹ç¼˜é«˜å…‰ï¼Œå¥¢åæ„Ÿ
çº¹ç†ï¼šæ‹‰ä¸é‡‘å±æˆ–å¤§ç†çŸ³æš—ç¤º
æ°›å›´ï¼šé«˜ç«¯ã€å¥¢åã€å“è´¨å“è¶Š""",
            
            "æ¸…æ–°å¤©è“ (Fresh Sky)": """èƒŒæ™¯ï¼šæµ…è“æ¸å˜(#e8f4f8â†’#d4ecf7â†’#b8dced)
å…‰æ•ˆï¼šæ˜äº®å‡åŒ€ï¼Œæ¸…çˆ½æ„Ÿ
å…ƒç´ ï¼šæŸ”å’Œäº‘æœµæ„Ÿï¼Œæ¸…æ–°ç©ºæ°”
æ°›å›´ï¼šå¤æ—¥ã€æ¸…å‡‰ã€è½»ç›ˆé€æ°”""",
            
            "æ°›å›´åœºæ™¯ (Lifestyle Scene)": """åœºæ™¯ï¼šå’–å•¡æ¯/ä¹¦æ¡Œ/æµ´å®¤/å§å®¤èå…¥
äº§å“ï¼šè‡ªç„¶æ”¾ç½®ä½†æ˜ç¡®ä¸ºä¸»è§’
æ™¯æ·±ï¼šæµ…æ™¯æ·±ï¼Œäº§å“é”åˆ©èƒŒæ™¯æŸ”å’Œ
å…‰çº¿ï¼šè‡ªç„¶çª—å…‰æˆ–æ¸©æš–å®¤å†…å…‰""",
            
            "ç¡¬æ ¸æ·±æ£• (Hardcore Brown)": """èƒŒæ™¯ï¼šæ·±æ£•æ¸å˜(#3d2b1fâ†’#5c4033)
çº¹ç†ï¼šçš®é©ã€å¤§åœ°ã€ç²—çŠ·è¡¨é¢
å…‰æ•ˆï¼šæ©™ç¥ç€è‰²ç‚¹å…‰æº
æ°›å›´ï¼šè¿åŠ¨ã€æˆ·å¤–ã€ç¡¬æ ¸ç”·æ€§""",
            
            "æç®€çº¯å‡€ (Minimal Pure)": """èƒŒæ™¯ï¼šçº¯ç™½#ffffffæˆ–æµ…ç°#f8f8f8
æ•ˆæœï¼šä»…äº§å“é˜´å½±ï¼Œæ— æ¸å˜æ— ç‰¹æ•ˆ
é£æ ¼ï¼šäºšé©¬é€Šåˆè§„é£æ ¼ï¼Œå‚æ•°ä¸ºä¸»
æ°›å›´ï¼šå¹²å‡€ã€ä¸“ä¸šã€è§„æ ¼å¯¼å‘""",
            
            "æœªæ¥ç§‘å¹» (Sci-Fi Future)": """èƒŒæ™¯ï¼šæ·±ç©ºè‰²å½©ï¼Œæ˜Ÿäº‘æš—ç¤º
çº¹ç†ï¼šè¡Œæ˜Ÿè¡¨é¢ã€å¤–æ˜Ÿåœ°å½¢
å…‰æ•ˆï¼šéœ“è™¹å…‰æ™•ï¼Œå…¨æ¯æš—ç¤º
æ°›å›´ï¼šå‰æ²¿ç§‘æŠ€ã€æ¸¸æˆã€ç¡¬æ ¸""",
        }
        style_instruction = style_details.get(design_style, "æ ¹æ®äº§å“ç‰¹æ€§é€‰æ‹©åˆé€‚çš„è§†è§‰é£æ ¼ã€‚")

        # ä»·æ ¼å±•ç¤ºå¤„ç†
        price_instructions = {
            "å¤§ä¿ƒä»·æ ¼å— (Â¥XX + åˆ’çº¿åŸä»·)": f"""ä»·æ ¼å±•ç¤ºï¼šå¤§ä¿ƒä»·æ ¼å—
- ä¿ƒé”€ä»·ï¼š{price_value}ï¼Œçº¢/æ©™è‰²ï¼Œ42ptç­‰æ•ˆå¤§å­—
- åŸä»·ï¼š{original_price}ï¼Œç°è‰²åˆ’çº¿ï¼Œ18pt
- èŠ‚çœæç¤ºï¼šç«‹çœXXå…ƒï¼ˆç»¿è‰²å°å­—ï¼‰
- ä½ç½®ï¼šåº•éƒ¨ä¸­å¤®æˆ–å·¦ä¸‹è§’""",
            
            "è§’æ ‡ä¿ƒé”€ä»· (å·¦ä¸‹åœ†è§’æ¡†)": f"""ä»·æ ¼å±•ç¤ºï¼šè§’æ ‡ä¿ƒé”€ä»·
- ä»·æ ¼ï¼š{price_value}ï¼Œåœ†è§’çŸ©å½¢èƒŒæ™¯æ¡†å†…
- ä½ç½®ï¼šå·¦ä¸‹è§’
- æŠ˜æ‰£è§’æ ‡ï¼šé™„ç€åœ¨ä»·æ ¼æ¡†ä¸Š""",
            
            "åŒä»·å¯¹æ¯” (å›½è¡¥ä»· vs åŸä»·)": f"""ä»·æ ¼å±•ç¤ºï¼šåŒä»·å¯¹æ¯”
- å›½è¡¥ä»·/åˆ°æ‰‹ä»·ï¼š{price_value}ï¼ˆå¤§å­—ï¼Œå¼ºè°ƒï¼‰
- åŸä»·/å¸‚åœºä»·ï¼š{original_price}ï¼ˆå°å­—å¯¹æ¯”ï¼‰
- å¹¶æ’å±•ç¤ºï¼Œçªå‡ºä¼˜æƒ åŠ›åº¦""",
            
            "ä¸æ˜¾ç¤ºä»·æ ¼": "ä¸æ˜¾ç¤ºä»»ä½•ä»·æ ¼ä¿¡æ¯ï¼Œä¸“æ³¨äº§å“ä»·å€¼ä¼ è¾¾ã€‚",
        }
        price_instruction = price_instructions.get(price_display, "ä¸æ˜¾ç¤ºä»·æ ¼ã€‚")

        # ä¿ƒé”€æ ‡ç­¾å¤„ç†
        promo_instructions = {
            "TOPæ’åå¾½ç«  (çƒ­é”€ç¬¬1å)": """ä¿ƒé”€æ ‡ç­¾ï¼šTOPæ’åå¾½ç« 
- æ ·å¼ï¼šé‡‘è‰²/çº¢è‰²ä¸å¸¦æˆ–ç›¾å½¢å¾½ç« 
- æ–‡æ¡ˆï¼š"TOP1" / "çƒ­é”€ç¬¬1å" / "é™å™ªæ•ˆæœ:ç¬¬1å"
- ä½ç½®ï¼šå³ä¸Šè§’æˆ–äº§å“æ—è¾¹
- æ•ˆæœï¼šå¾®å¦™é‡‘å±è´¨æ„Ÿï¼ŒæŠ•å½±""",
            
            "é™æ—¶æŠ˜æ‰£æ ‡ç­¾ (é™æ—¶XæŠ˜/ç«‹å‡XX)": """ä¿ƒé”€æ ‡ç­¾ï¼šé™æ—¶æŠ˜æ‰£
- æ ·å¼ï¼šæ–œè§’é£˜å¸¦æˆ–é†’ç›®å¾½ç« 
- æ–‡æ¡ˆï¼š"é™æ—¶87æŠ˜" / "ç«‹å‡60å…ƒ" / "é™æ—¶ç‰¹æƒ "
- é¢œè‰²ï¼šçº¢/æ©™æ¸å˜ï¼Œç™½è‰²æ–‡å­—
- ä½ç½®ï¼šå³ä¾§ç«–æ’æˆ–å³ä¸Šè§’""",
            
            "ä¹°èµ æ´»åŠ¨æ¡† (ä¹°2èµ 1)": """ä¿ƒé”€æ ‡ç­¾ï¼šä¹°èµ æ´»åŠ¨
- æ ·å¼ï¼šåœ†è§’çŸ©å½¢æ¨ªå¹…
- æ–‡æ¡ˆï¼š"ä¹°2èµ 1" / "ä¹°3å¢2" / "åŠ è´­é€XX"
- é¢œè‰²ï¼šä¿ƒé”€çº¢æˆ–å“ç‰Œè‰²
- ä½ç½®ï¼šäº§å“ä¸Šæ–¹æˆ–ä¸‹æ–¹""",
            
            "æ–°å“é¦–å‘æ ‡ç­¾": """ä¿ƒé”€æ ‡ç­¾ï¼šæ–°å“é¦–å‘
- æ ·å¼ï¼šç®€æ´æ ‡ç­¾æˆ–è§’æ ‡
- æ–‡æ¡ˆï¼š"æ–°å“" / "é¦–å‘" / "NEW"
- çªå‡ºæ–°é²œæ„Ÿå’Œç‹¬ç‰¹æ€§""",
            
            "å®˜æ–¹æ­£å“å¾½ç« ": """ä¿ƒé”€æ ‡ç­¾ï¼šå®˜æ–¹æ­£å“
- æ ·å¼ï¼šè®¤è¯å¾½ç« é£æ ¼
- æ–‡æ¡ˆï¼š"å®˜æ–¹æ­£å“" / "å“ç‰Œæˆæƒ" / "å®˜æ–¹æ——èˆ°"
- å¢å¼ºä¿¡ä»»æ„Ÿ""",
            
            "è®¤è¯æ ‡ç­¾ (ACS/SGS/Hi-Res)": """ä¿ƒé”€æ ‡ç­¾ï¼šä¸“ä¸šè®¤è¯
- æ ·å¼ï¼šè®¤è¯æœºæ„å®˜æ–¹æ ‡è¯†é£æ ¼
- ç±»å‹ï¼šACS/SGS/Hi-Res/CEç­‰è®¤è¯å›¾æ ‡
- ä½ç½®ï¼šäº§å“æ—æˆ–è§„æ ¼åŒº
- å¢å¼ºä¸“ä¸šå¯ä¿¡åº¦""",
            
            "æ— ä¿ƒé”€æ ‡ç­¾": "ä¸æ·»åŠ ä¿ƒé”€æ ‡ç­¾ï¼Œä¿æŒç”»é¢å¹²å‡€ç®€æ´ï¼Œä¸“æ³¨äº§å“æœ¬èº«ã€‚",
        }
        promo_instruction = promo_instructions.get(promo_type, "ä¸æ·»åŠ ä¿ƒé”€æ ‡ç­¾ã€‚")

        # ä¿¡ä»»æ¨ªæ¡å¤„ç†
        trust_instruction = f"""ä¿¡ä»»æ¨ªæ¡ï¼š
- ä½ç½®ï¼šåº•éƒ¨10%åŒºåŸŸ
- å¸ƒå±€ï¼šæ°´å¹³å‡åŒ€åˆ†å¸ƒ
- å†…å®¹ï¼š{trust_bar}
- æ ·å¼ï¼šå°å›¾æ ‡+æ–‡å­—ï¼Œå¾®å¦™èƒŒæ™¯æ¡"""

        try:
            target_count = int(prompt_count)
        except Exception:
            target_count = 3
        target_count = max(1, min(10, target_count))

        # å˜ä½“è§„åˆ’
        if target_count == 1:
            variant_plan = """ç”Ÿæˆ1ä¸ªå˜ä½“ - ä¸»å›¾é¦–é€‰(Hero Prime)ï¼š
- æœ€ä½³45Â°è§’åº¦å±•ç¤ºäº§å“ç«‹ä½“æ„Ÿ
- æœ€å¼ºè§†è§‰å†²å‡»ä¸»æ ‡é¢˜
- æœ€ä¼˜ä»·æ ¼ä¿ƒé”€å¸ƒå±€ç»„åˆ"""
        elif target_count == 2:
            variant_plan = """ç”Ÿæˆ2ä¸ªå˜ä½“ï¼š
V1 - ä¸»å›¾é¦–é€‰(Hero Prime)ï¼š45Â°æœ€ä½³è§’åº¦ï¼Œä¸»ä»·å€¼ä¸»å¼ ï¼Œå®Œæ•´ä¿ƒé”€å¸ƒå±€
V2 - å–ç‚¹ç‰¹å†™(Feature Spotlight)ï¼šå…³é”®å·®å¼‚åŒ–ç‰¹å†™ï¼ŒæŠ€æœ¯ç»†èŠ‚å±•ç¤º"""
        elif target_count == 3:
            variant_plan = """ç”Ÿæˆ3ä¸ªå˜ä½“ï¼š
V1 - ä¸»å›¾é¦–é€‰(Hero Prime)ï¼š45Â°æœ€ä½³è§’åº¦ï¼Œä¸»ä»·å€¼ä¸»å¼ 
V2 - å–ç‚¹ç‰¹å†™(Feature Spotlight)ï¼šå…³é”®ç‰¹æ€§è¿‘è·ç‰¹å†™
V3 - ä¿¡ä»»èƒŒä¹¦(Trust Builder)ï¼šTOPå¾½ç« +è®¤è¯çªå‡ºå±•ç¤º"""
        else:
            variant_plan = f"""ç”Ÿæˆ{target_count}ä¸ªå˜ä½“ï¼š
V1 - ä¸»å›¾é¦–é€‰(Hero Prime)ï¼š45Â°æœ€ä½³è§’åº¦ï¼Œä¸»ä»·å€¼ä¸»å¼ 
V2 - å–ç‚¹ç‰¹å†™(Feature Spotlight)ï¼šå…³é”®ç‰¹æ€§è¿‘è·ç‰¹å†™
V3 - ä¿¡ä»»èƒŒä¹¦(Trust Builder)ï¼šTOPå¾½ç« +è®¤è¯çªå‡º
V4 - ä¿ƒé”€ä¸»æ‰“(Price Focus)ï¼šå¤§ä¿ƒä»·æ ¼ä¸ºè§†è§‰ä¸­å¿ƒ
V5 - åœºæ™¯æ°›å›´(Lifestyle Context)ï¼šä½¿ç”¨åœºæ™¯èå…¥
V6+ - è§’åº¦å˜åŒ–(Angle Variation)ï¼šå…¶ä»–è§’åº¦å±•ç¤º"""

        # æ„å»ºå®Œæ•´è¯·æ±‚
        base_user_req = f"""
è¯·ä¸ºä»¥ä¸‹äº§å“ç”Ÿæˆ {{COUNT}} ä¸ªé«˜è§†è§‰å†²å‡»åŠ›ç”µå•†ä¸»å›¾æç¤ºè¯ï¼š

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€äº§å“ä¿¡æ¯ã€‘
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
- äº§å“ç±»å‹ï¼š{product_type}
- æ ¸å¿ƒå–ç‚¹ï¼š{selling_points}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€è§†è§‰è§„èŒƒ - å¿…é¡»ä¸¥æ ¼éµå®ˆã€‘
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€è®¾è®¡é£æ ¼ã€‘
{design_style}
{style_instruction}

ã€ç”»å¹…æ¯”ä¾‹ã€‘{ratio_code}
{ratio_instruction}

ã€ä»·æ ¼å±•ç¤ºã€‘
{price_instruction}

ã€ä¿ƒé”€æ ‡ç­¾ã€‘
{promo_instruction}

ã€ä¿¡ä»»æ¨ªæ¡ã€‘
{trust_instruction}

ã€è¯­è¨€è¦æ±‚ã€‘
{lang_instruction}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€å˜ä½“è§„åˆ’ã€‘
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{variant_plan}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€å‚è€ƒå›¾ä¿¡æ¯ã€‘
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
å‚è€ƒå›¾æ•°é‡ï¼š{len(base64_images)}
è§„åˆ™ï¼šä¸¥æ ¼ä»¥å‚è€ƒå›¾ä¸ºäº§å“å¤–è§‚ä¾æ®ï¼Œéš”ç¦»äº§å“ä¸»ä½“åé‡å»ºèƒŒæ™¯ï¼Œæ‰€æœ‰å˜ä½“ä¿æŒå¤–è§‚ä¸€è‡´ã€‚

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€è¾“å‡ºæ ¼å¼è¦æ±‚ - ä¸¥æ ¼éµå®ˆã€‘
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. è¾“å‡ºçº¯JSONå­—ç¬¦ä¸²åˆ—è¡¨ List[str]ï¼Œé•¿åº¦å¿…é¡»ç­‰äº {{COUNT}}
2. ä¸è¦è¾“å‡ºMarkdownã€ä»£ç å—ã€ä»»ä½•è§£é‡Šæ–‡å­—
3. æ¯ä¸ªå˜ä½“æ˜¯ä¸€ä¸ªå®Œæ•´æç¤ºè¯å­—ç¬¦ä¸²

ã€æ¯ä¸ªå˜ä½“å¿…é¡»åŒ…å«6ä¸ªæ¨¡å—ã€‘
1) ä¸»æ ‡é¢˜: "..." (42ptç­‰æ•ˆå¤§å­—ï¼Œ4-12å­—ï¼Œè§†è§‰å†²å‡»åŠ›)
2) å‰¯æ ‡é¢˜: "..." (18-24ptï¼Œ3-5ä¸ªå–ç‚¹/è§„æ ¼ï¼Œç®¡é“ç¬¦æˆ–å›¾æ ‡åˆ†éš”)
3) ä»·æ ¼ä¿ƒé”€åŒº: æŒ‰ä¸Šæ–¹è§„èŒƒè¯¦ç»†æè¿°ä»·æ ¼å±•ç¤ºæ–¹å¼ã€æ ‡ç­¾ç±»å‹ä½ç½®ã€ä¿¡ä»»æ¡
4) æ’ç‰ˆè“å›¾: ä¸¥æ ¼æŒ‰{ratio_code}æ¯”ä¾‹è§„èŒƒï¼Œæè¿°äº§å“ä½ç½®(å æ¯”45-60%)ã€æ–‡å­—åŒºåˆ’åˆ†ã€æ ‡ç­¾ä½ç½®
5) è§†è§‰ä¸å…‰å½±: æŒ‰é£æ ¼è§„èŒƒè¯¦è¿°èƒŒæ™¯ã€ä¸»å…‰/è¡¥å…‰/è½®å»“å…‰è®¾ç½®ã€äº§å“æ‚¬æµ®æ•ˆæœ(ä¸Šæµ®15-30px+æ¤­åœ†æŸ”å½±)ã€æè´¨æ¸²æŸ“ã€é…è‰²
6) æ¸²æŸ“å“è´¨: 8Kè¶…æ¸…å•†ä¸šæ‘„å½±çº§ã€æè´¨ç»†èŠ‚æ¸…æ™°å¯è§ã€æ–‡å­—42pté”åˆ©æ— é”¯é½¿ã€ä¸“ä¸šè°ƒè‰²ã€è§†è§‰å†²å‡»è¯„åˆ†9/10

ã€å˜ä½“å®šä½æ ‡ç­¾ã€‘
æ¯ä¸ªå˜ä½“å¼€å¤´æ ‡æ³¨å®šä½ï¼š
ä¸­æ–‡ï¼š"å˜ä½“å®šä½ï¼šä¸»å›¾é¦–é€‰" / "å˜ä½“å®šä½ï¼šå–ç‚¹ç‰¹å†™" / "å˜ä½“å®šä½ï¼šä¿¡ä»»èƒŒä¹¦" / "å˜ä½“å®šä½ï¼šä¿ƒé”€ä¸»æ‰“" / "å˜ä½“å®šä½ï¼šåœºæ™¯æ°›å›´"
è‹±æ–‡ï¼š"Variant Role: Hero Prime" / "Variant Role: Feature Spotlight" ç­‰

ã€é˜²ä¹±ç ç»“å°¾ã€‘
æ¯ä¸ªæç¤ºè¯æœ«å°¾è¿½åŠ ï¼š{anti_translate}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€è´¨é‡æ ‡å‡† - ä¸å¯å¦¥åã€‘
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â–¡ ä¸»æ ‡é¢˜42ptç­‰æ•ˆï¼Œé†’ç›®ç¨‹åº¦ä¸å¯å¿½è§†
â–¡ äº§å“æ‚¬æµ®æ•ˆæœä¸“ä¸šï¼Œå æ¯”45-60%
â–¡ ä¸‰ç‚¹å¸ƒå…‰è¥é€ ç«‹ä½“æ„Ÿå’Œé«˜çº§æ„Ÿ
â–¡ èƒŒæ™¯é£æ ¼ä¸¥æ ¼åŒ¹é…è§„èŒƒ
â–¡ ä»·æ ¼ä¿ƒé”€æ¸…æ™°ä½†ä¸æŠ¢äº§å“é£å¤´
â–¡ æ’ç‰ˆä¸¥æ ¼é€‚é…{ratio_code}æ¯”ä¾‹
â–¡ è§†è§‰å†²å‡»åŠ›è¯„åˆ†ç›®æ ‡ï¼š9/10
â–¡ å¯¹æ ‡è‹¹æœ/æˆ´æ£®çº§å•†ä¸šæ‘„å½±å“è´¨
"""

        collected = []
        raw_responses = []
        attempts = []
        max_per_call = 5
        max_calls = 5
        call_idx = 0
        last_error = None

        while len(collected) < target_count and call_idx < max_calls:
            remaining = target_count - len(collected)
            request_n = remaining if remaining <= max_per_call else max_per_call

            user_req = base_user_req.replace("{COUNT}", str(request_n))
            if len(collected) > 0:
                user_req += f"\n\nã€ç»­å†™è¦æ±‚ã€‘è¿™æ˜¯ç»­å†™ç”Ÿæˆï¼Œè¯·ç”Ÿæˆæ–°çš„{request_n}ä¸ªå˜ä½“ï¼Œä¸è¦é‡å¤ä¹‹å‰çš„è§’åº¦ã€æ ‡é¢˜ä¸æ„å›¾ã€‚"

            print(f"ğŸ¨ Generating {request_n} premium main image variants... ({len(collected)}/{target_count})")
            result = self.call_llm_vision(api_url, api_key, model_name, system_instruction, user_req, base64_images if base64_images else None, seed)
            call_idx += 1

            if not result["success"]:
                last_error = result.get("error")
                attempts.append({
                    "call": call_idx,
                    "requested": request_n,
                    "parsed": 0,
                    "accepted": 0,
                    "method": "api_error",
                    "error": last_error,
                })
                continue

            response = result.get("content", "")
            raw_responses.append(response)

            batch_prompts, method = self._parse_response_to_prompts_list(response, request_n)

            accepted = []
            rejected = 0
            for p in batch_prompts:
                if self._is_prompt_structurally_complete(p):
                    accepted.append(p)
                else:
                    rejected += 1

            if not accepted and batch_prompts:
                accepted = batch_prompts

            if len(accepted) > request_n:
                accepted = accepted[:request_n]

            collected.extend(accepted)

            attempts.append({
                "call": call_idx,
                "requested": request_n,
                "parsed": len(batch_prompts),
                "accepted": len(accepted),
                "rejected": rejected,
                "method": method,
                "response_chars": len(response) if isinstance(response, str) else None,
            })

        if len(collected) > target_count:
            collected = collected[:target_count]

        if len(collected) < target_count:
            missing = target_count - len(collected)
            msg = "[GENERATION_FAILED] Unable to generate enough variants."
            if last_error:
                msg = f"[GENERATION_FAILED] {last_error}"
            collected.extend([msg] * missing)

        debug_payload = {
            "plugin": "Comfyui-WL-MainImageDesign v2.0",
            "input_summary": {
                "product": product_type,
                "style": design_style,
                "ratio": ratio_code,
                "target_count": target_count,
            },
            "reference_image_count": len(base64_images),
            "attempts": attempts,
        }
        if raw_responses:
            debug_payload["raw_response_preview"] = raw_responses[-1][:2000] if len(raw_responses[-1]) > 2000 else raw_responses[-1]
        if last_error:
            debug_payload["error"] = last_error

        return (collected, json.dumps(debug_payload, ensure_ascii=False, indent=2))


class WLPromptBatchConverter:
    """æç¤ºè¯åˆ—è¡¨è½¬æ‰¹æ¬¡å¤„ç†å™¨"""
    
    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "prompts_list": ("STRING", {
                    "forceInput": True,
                    "multiline": True,
                    "placeholder": "è¾“å…¥æç¤ºè¯åˆ—è¡¨"
                }),
                "batch_size": ("INT", {
                    "default": 5,
                    "min": 1,
                    "max": 20,
                    "tooltip": "æ¯æ‰¹å¤„ç†æ•°é‡"
                }),
            }
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("batch_output",)
    OUTPUT_IS_LIST = (False,)

    FUNCTION = "convert_list_to_batches"
    CATEGORY = "ğŸ¨ WL-MainImageDesign"

    def convert_list_to_batches(self, prompts_list, batch_size):
        if not prompts_list or not prompts_list.strip():
            return ("Error: No prompts list provided",)
        
        try:
            if prompts_list.strip().startswith('['):
                try:
                    prompts = json.loads(prompts_list)
                    if isinstance(prompts, list):
                        prompt_items = prompts
                    else:
                        prompt_items = [str(prompts)]
                except json.JSONDecodeError:
                    prompt_items = [line.strip() for line in prompts_list.split('\n') if line.strip()]
            else:
                prompt_items = [line.strip() for line in prompts_list.split('\n') if line.strip()]
            
            if not prompt_items:
                return ("Error: No valid prompts found",)
            
            batches = []
            for i in range(0, len(prompt_items), batch_size):
                batch = prompt_items[i:i + batch_size]
                batches.append('\n'.join(batch))
            
            result = ""
            for i, batch in enumerate(batches):
                if i > 0:
                    result += "\n---\n"
                result += batch
            
            return (result,)
            
        except Exception as e:
            return (f"Error: {str(e)}",)


NODE_CLASS_MAPPINGS = {
    "WLMainImageGenerator": WLMainImageGenerator,
    "WLPromptBatchConverter": WLPromptBatchConverter
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "WLMainImageGenerator": "ğŸ¨ WL Main Image Designer",
    "WLPromptBatchConverter": "ğŸ”„ WL Prompt Batch Converter"
}
